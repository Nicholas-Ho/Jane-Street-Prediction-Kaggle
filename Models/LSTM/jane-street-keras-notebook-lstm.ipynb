{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jane Street Market Prediction - An LSTM Approach\n",
    "*This notebook is a response to the problem posed by the \"Jane Street Market Prediction\" Kaggle Competition (Nov 2020 - Feb 2021).*\n",
    "\n",
    "The applications of Deep Learning in financial markets has always been one of the hot topics of the field. The Jane Street Market Prediction competition challenges us to create a quantitative trading model, one that utilizes real-time market data to help make trading decisions and maximise returns.\n",
    "\n",
    "### Framing the Problem\n",
    "\n",
    "The goal of the model is to **predict whether it is better to make a trade or pass on it** at a certain point in time, given an anonymized set of features representing stock market data at that point.\n",
    "\n",
    "I opted to use a **Long Short-Term Memory (LSTM)** model because market data is a Time Series. Analysing past patterns to predict future performance is already established in Fundamental market analysis, so I decided to have the model take into account past data in addition to current data.\n",
    "\n",
    "Below, I go through the preparation of data, model creation and finally prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning the Dataset\n",
    "\n",
    "We first have to import the dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable\n",
    "\n",
    "# datatable reads large csv files faster than pandas\n",
    "train_df = datatable.fread('Data/train.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2390491 entries, 0 to 2390490\n",
      "Columns: 138 entries, date to ts_id\n",
      "dtypes: float64(135), int32(3)\n",
      "memory usage: 2.4 GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3         -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `date` is the day on which the trading opportunity occurs. This goes from Day 0-499.\n",
    "\n",
    "The `weight` and `resp` together represent the value of each trade. `resp_1` to `resp_4` are 'resp' values over different time horizons. **The five 'resp' values will be the dependent variables, and hence the targets of prediction.**\n",
    "\n",
    "`feature_0` to `feature_129` represent stock market data.\n",
    "\n",
    "The `ts_id` is the index of each row. It is the number representing the time of the trading opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = train_df.mean().drop(['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'date', 'ts_id']) # Will be used later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaN entries\n",
    "\n",
    "Right away we see that we will have to deal with numerous NaN entries, as seen in feature_121. Let's dig a little deeper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_3         448\n",
       "feature_4         448\n",
       "feature_7      393135\n",
       "feature_8      393135\n",
       "feature_9         788\n",
       "                ...  \n",
       "feature_125     16083\n",
       "feature_126      8853\n",
       "feature_127      8853\n",
       "feature_128      1921\n",
       "feature_129      1921\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_df = train_df.isnull().sum()\n",
    "isna_df[isna_df > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 395535\n",
      "feature_17    395535\n",
      "feature_18    395535\n",
      "feature_27    395535\n",
      "feature_28    395535\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0011989987212559733"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Max:\", isna_df.max())\n",
    "print(isna_df[isna_df == isna_df.max()])\n",
    "isna_df.max()/train_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 88 columns with NaN entries, with the a maximum of 395535 NaN entries in a single column. However, this is 0.1% of the whole dataset, so it should be okay to fill in the NaN entries.\n",
    "\n",
    "An analysis by Tom Warrens strongly suggests that most NaN values occur at the start of the day and during midday, which corresponds to the market opening and lunch breaks. With this information, it makes sense to fill in the NaN values with the last valid observation.\n",
    "\n",
    "However, this only holds true if data is at least generally continuous. Carl McBride's Day 0 Exploratory Data Analysis workbook shows that this is not always the case. `feature_41` to `feature_45` comprise of discrete value. For these features, it makes more sense to fill in NaN values with the mean.\n",
    "\n",
    "*Tom Warrens' analysis can be found here: https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day*\n",
    "\n",
    "*Carl McBride's Day 0 EDA can be found here: https://www.kaggle.com/carlmcbrideellis/jane-street-eda-of-day-0-and-feature-importance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_44    448\n",
       "feature_45    448\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features = ['feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45']\n",
    "\n",
    "isna_df = train_df[discrete_features].isnull().sum()\n",
    "isna_df[isna_df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are discrete features with NaN entries, we need to take two different approaches to filling in the data: forward-filling the continuous data and filling with mean for the discrete data.\n",
    "\n",
    "We deal with the discrete data first.\n",
    "\n",
    "*Note: For the sake of simplicity in this notebook, I split the data into training and validation datasets and fill with the mean before concatenating again. This is to prevent **data leakage** that occurs when the mean used to fill in the values is the mean of the whole dataset, rather than just the training set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jxion\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3         -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling with mean for discrete data\n",
    "def fill_na_mean_discrete(df, discrete_features):\n",
    "    df[discrete_features] = df[discrete_features].fillna(value=df[discrete_features].mean())\n",
    "    return df\n",
    "\n",
    "# Splitting into validation and training datasets to prevent data leakage\n",
    "valid_ratio = 0.1 # 90% training data, 10% validation data\n",
    "valid_index = int(len(train_df.index) * (1 - valid_ratio))\n",
    "\n",
    "valid_df = fill_na_mean_discrete(train_df[valid_index:], discrete_features)\n",
    "train_df = fill_na_mean_discrete(train_df[0:valid_index], discrete_features)\n",
    "\n",
    "# Re-concatenating both datasets\n",
    "train_df = pd.concat([train_df, valid_df], axis=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_df = train_df[discrete_features].isnull().sum()\n",
    "isna_df[isna_df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use forward-filling to fill the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...          NaN     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...          NaN    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...          NaN     6.115747   \n",
       "3         -1   1.174378   0.344640  ...          NaN     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...          NaN     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward-filling\n",
    "train_df.fillna(method=\"ffill\", inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_7      476\n",
       "feature_8      476\n",
       "feature_11      72\n",
       "feature_12      72\n",
       "feature_17     479\n",
       "feature_18     479\n",
       "feature_21      74\n",
       "feature_22      74\n",
       "feature_27     479\n",
       "feature_28     479\n",
       "feature_31      74\n",
       "feature_32      74\n",
       "feature_55      99\n",
       "feature_72     476\n",
       "feature_74      72\n",
       "feature_78     476\n",
       "feature_80      72\n",
       "feature_84     476\n",
       "feature_86      72\n",
       "feature_90     476\n",
       "feature_92      72\n",
       "feature_96     476\n",
       "feature_98      72\n",
       "feature_102    476\n",
       "feature_104     72\n",
       "feature_108    476\n",
       "feature_110     72\n",
       "feature_114    476\n",
       "feature_116     72\n",
       "feature_120     99\n",
       "feature_121     99\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_df = train_df.isnull().sum()\n",
    "isna_df[isna_df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of NaN entries has been drastically reduced, but there are still many entries with NaN values. This is likely because many NaN values start at index 0 (as can be seen from `feature_121` above) and hence do not have a last valid observation to fill from.\n",
    "\n",
    "Although this is not ideal since in actual use we will not have future data on hand, for training purposes we can fill in the last few NaN entries with the next valid observation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095326</td>\n",
       "      <td>1.168391</td>\n",
       "      <td>8.313583</td>\n",
       "      <td>1.782433</td>\n",
       "      <td>14.018213</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>12.600292</td>\n",
       "      <td>2.301488</td>\n",
       "      <td>11.445807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.673515</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095326</td>\n",
       "      <td>-1.178850</td>\n",
       "      <td>1.777472</td>\n",
       "      <td>-0.915458</td>\n",
       "      <td>2.831612</td>\n",
       "      <td>-1.417010</td>\n",
       "      <td>2.297459</td>\n",
       "      <td>-1.304614</td>\n",
       "      <td>1.898684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025134</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095326</td>\n",
       "      <td>6.115747</td>\n",
       "      <td>9.667908</td>\n",
       "      <td>5.542871</td>\n",
       "      <td>11.671595</td>\n",
       "      <td>7.281757</td>\n",
       "      <td>10.060014</td>\n",
       "      <td>6.638248</td>\n",
       "      <td>9.427299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095326</td>\n",
       "      <td>2.838853</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>3.033732</td>\n",
       "      <td>1.513488</td>\n",
       "      <td>4.397532</td>\n",
       "      <td>1.266037</td>\n",
       "      <td>3.856384</td>\n",
       "      <td>1.013469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138531</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095326</td>\n",
       "      <td>0.344850</td>\n",
       "      <td>4.101145</td>\n",
       "      <td>0.614252</td>\n",
       "      <td>6.623456</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>5.233243</td>\n",
       "      <td>0.362636</td>\n",
       "      <td>3.926633</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "0     0   0.000000  0.009916  0.014079  0.008773  0.001390  0.006270   \n",
       "1     0  16.673515 -0.002828 -0.003226 -0.007319 -0.011114 -0.009792   \n",
       "2     0   0.000000  0.025134  0.027607  0.033406  0.034380  0.023970   \n",
       "3     0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003200   \n",
       "4     0   0.138531  0.001252  0.002165 -0.001215 -0.006219 -0.002604   \n",
       "\n",
       "   feature_0  feature_1  feature_2  ...  feature_121  feature_122  \\\n",
       "0          1  -1.872746  -2.191242  ...     2.095326     1.168391   \n",
       "1         -1  -1.349537  -1.704709  ...     2.095326    -1.178850   \n",
       "2         -1   0.812780  -0.256156  ...     2.095326     6.115747   \n",
       "3         -1   1.174378   0.344640  ...     2.095326     2.838853   \n",
       "4          1  -3.172026  -3.093182  ...     2.095326     0.344850   \n",
       "\n",
       "   feature_123  feature_124  feature_125  feature_126  feature_127  \\\n",
       "0     8.313583     1.782433    14.018213     2.653056    12.600292   \n",
       "1     1.777472    -0.915458     2.831612    -1.417010     2.297459   \n",
       "2     9.667908     5.542871    11.671595     7.281757    10.060014   \n",
       "3     0.499251     3.033732     1.513488     4.397532     1.266037   \n",
       "4     4.101145     0.614252     6.623456     0.800129     5.233243   \n",
       "\n",
       "   feature_128  feature_129  ts_id  \n",
       "0     2.301488    11.445807      0  \n",
       "1    -1.304614     1.898684      1  \n",
       "2     6.638248     9.427299      2  \n",
       "3     3.856384     1.013469      3  \n",
       "4     0.362636     3.926633      4  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.fillna(method=\"bfill\", inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_df = train_df.isnull().sum()\n",
    "isna_df[isna_df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Memory Usage\n",
    "\n",
    "Before we continue, we should return to the memory usage of the dataset, as seen above. At 2.4GB, the training dataset takes up quite a lot of memory. Let's try to reduce the memory usage by optimizing the data types.\n",
    "\n",
    "(Note: if done before we fill the NaN entries, the pandas.fillna method will not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2390491 entries, 0 to 2390490\n",
      "Columns: 138 entries, date to ts_id\n",
      "dtypes: float16(135), int16(1), int32(1), int8(1)\n",
      "memory usage: 631.5 MB\n"
     ]
    }
   ],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                    \n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "            \n",
    "    return df\n",
    "\n",
    "train_df = reduce_memory_usage(train_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-indexing the Data\n",
    "\n",
    "Lastly, we should set the index of train_df to \"ts_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.873047</td>\n",
       "      <td>-2.191406</td>\n",
       "      <td>...</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>1.167969</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>1.782227</td>\n",
       "      <td>14.015625</td>\n",
       "      <td>2.652344</td>\n",
       "      <td>12.601562</td>\n",
       "      <td>2.300781</td>\n",
       "      <td>11.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16.671875</td>\n",
       "      <td>-0.002829</td>\n",
       "      <td>-0.003227</td>\n",
       "      <td>-0.007320</td>\n",
       "      <td>-0.011116</td>\n",
       "      <td>-0.009789</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349609</td>\n",
       "      <td>-1.705078</td>\n",
       "      <td>...</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>-1.178711</td>\n",
       "      <td>1.777344</td>\n",
       "      <td>-0.915527</td>\n",
       "      <td>2.832031</td>\n",
       "      <td>-1.416992</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>-1.304688</td>\n",
       "      <td>1.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.033417</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812988</td>\n",
       "      <td>-0.256104</td>\n",
       "      <td>...</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>6.117188</td>\n",
       "      <td>9.664062</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>11.671875</td>\n",
       "      <td>7.281250</td>\n",
       "      <td>10.062500</td>\n",
       "      <td>6.636719</td>\n",
       "      <td>9.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>-0.003201</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174805</td>\n",
       "      <td>0.344727</td>\n",
       "      <td>...</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>2.837891</td>\n",
       "      <td>0.499268</td>\n",
       "      <td>3.033203</td>\n",
       "      <td>1.513672</td>\n",
       "      <td>4.398438</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>3.855469</td>\n",
       "      <td>1.013672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138550</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>-0.006218</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.171875</td>\n",
       "      <td>-3.093750</td>\n",
       "      <td>...</td>\n",
       "      <td>5.542969</td>\n",
       "      <td>2.095703</td>\n",
       "      <td>0.344971</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>0.800293</td>\n",
       "      <td>5.234375</td>\n",
       "      <td>0.362549</td>\n",
       "      <td>3.925781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.649414</td>\n",
       "      <td>-1.169922</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.421875</td>\n",
       "      <td>-1.896484</td>\n",
       "      <td>-1.259766</td>\n",
       "      <td>1.947266</td>\n",
       "      <td>-1.994141</td>\n",
       "      <td>-1.685547</td>\n",
       "      <td>-2.865234</td>\n",
       "      <td>-0.216187</td>\n",
       "      <td>-1.891602</td>\n",
       "      <td>0.901367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.006325</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>1</td>\n",
       "      <td>2.433594</td>\n",
       "      <td>5.285156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677734</td>\n",
       "      <td>-0.936523</td>\n",
       "      <td>1.064453</td>\n",
       "      <td>3.119141</td>\n",
       "      <td>-0.419678</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>-0.146729</td>\n",
       "      <td>0.729980</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>2.068359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.622559</td>\n",
       "      <td>-0.963867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459229</td>\n",
       "      <td>-2.957031</td>\n",
       "      <td>-0.640137</td>\n",
       "      <td>-2.279297</td>\n",
       "      <td>-0.950195</td>\n",
       "      <td>-4.386719</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.289062</td>\n",
       "      <td>-1.335938</td>\n",
       "      <td>-2.814453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>499</td>\n",
       "      <td>0.283447</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.003702</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.463867</td>\n",
       "      <td>-1.107422</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.650391</td>\n",
       "      <td>-2.035156</td>\n",
       "      <td>-1.781250</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>-2.201172</td>\n",
       "      <td>-1.913086</td>\n",
       "      <td>-3.341797</td>\n",
       "      <td>-0.571289</td>\n",
       "      <td>-2.185547</td>\n",
       "      <td>0.627441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.817383</td>\n",
       "      <td>-1.131836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983887</td>\n",
       "      <td>-0.570801</td>\n",
       "      <td>2.484375</td>\n",
       "      <td>8.281250</td>\n",
       "      <td>-0.698730</td>\n",
       "      <td>0.199951</td>\n",
       "      <td>-0.168335</td>\n",
       "      <td>2.050781</td>\n",
       "      <td>1.725586</td>\n",
       "      <td>5.824219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390491 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     weight    resp_1    resp_2    resp_3    resp_4      resp  \\\n",
       "ts_id                                                                        \n",
       "0           0   0.000000  0.009918  0.014076  0.008774  0.001390  0.006271   \n",
       "1           0  16.671875 -0.002829 -0.003227 -0.007320 -0.011116 -0.009789   \n",
       "2           0   0.000000  0.025131  0.027603  0.033417  0.034393  0.023972   \n",
       "3           0   0.000000 -0.004730 -0.003273 -0.000461 -0.000476 -0.003201   \n",
       "4           0   0.138550  0.001252  0.002165 -0.001216 -0.006218 -0.002604   \n",
       "...       ...        ...       ...       ...       ...       ...       ...   \n",
       "2390486   499   0.000000  0.000142  0.000142  0.005829  0.020340  0.015396   \n",
       "2390487   499   0.000000  0.000012  0.000012 -0.000935 -0.006325 -0.004719   \n",
       "2390488   499   0.000000  0.000499  0.000499  0.007607  0.024902  0.016586   \n",
       "2390489   499   0.283447 -0.000156 -0.000156 -0.001375 -0.003702 -0.002005   \n",
       "2390490   499   0.000000 -0.001855 -0.001855 -0.001194 -0.000864 -0.001904   \n",
       "\n",
       "         feature_0  feature_1  feature_2  ...  feature_120  feature_121  \\\n",
       "ts_id                                     ...                             \n",
       "0                1  -1.873047  -2.191406  ...     5.542969     2.095703   \n",
       "1               -1  -1.349609  -1.705078  ...     5.542969     2.095703   \n",
       "2               -1   0.812988  -0.256104  ...     5.542969     2.095703   \n",
       "3               -1   1.174805   0.344727  ...     5.542969     2.095703   \n",
       "4                1  -3.171875  -3.093750  ...     5.542969     2.095703   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "2390486          1  -1.649414  -1.169922  ...    -2.421875    -1.896484   \n",
       "2390487          1   2.433594   5.285156  ...    -0.677734    -0.936523   \n",
       "2390488          1  -0.622559  -0.963867  ...    -0.459229    -2.957031   \n",
       "2390489         -1  -1.463867  -1.107422  ...    -2.650391    -2.035156   \n",
       "2390490         -1  -1.817383  -1.131836  ...    -0.983887    -0.570801   \n",
       "\n",
       "         feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "ts_id                                                                      \n",
       "0           1.167969     8.312500     1.782227    14.015625     2.652344   \n",
       "1          -1.178711     1.777344    -0.915527     2.832031    -1.416992   \n",
       "2           6.117188     9.664062     5.542969    11.671875     7.281250   \n",
       "3           2.837891     0.499268     3.033203     1.513672     4.398438   \n",
       "4           0.344971     4.101562     0.614258     6.625000     0.800293   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2390486    -1.259766     1.947266    -1.994141    -1.685547    -2.865234   \n",
       "2390487     1.064453     3.119141    -0.419678    -0.208984    -0.146729   \n",
       "2390488    -0.640137    -2.279297    -0.950195    -4.386719    -1.669922   \n",
       "2390489    -1.781250     0.881348    -2.201172    -1.913086    -3.341797   \n",
       "2390490     2.484375     8.281250    -0.698730     0.199951    -0.168335   \n",
       "\n",
       "         feature_127  feature_128  feature_129  \n",
       "ts_id                                           \n",
       "0          12.601562     2.300781    11.445312  \n",
       "1           2.296875    -1.304688     1.898438  \n",
       "2          10.062500     6.636719     9.429688  \n",
       "3           1.265625     3.855469     1.013672  \n",
       "4           5.234375     0.362549     3.925781  \n",
       "...              ...          ...          ...  \n",
       "2390486    -0.216187    -1.891602     0.901367  \n",
       "2390487     0.729980     0.648438     2.068359  \n",
       "2390488    -3.289062    -1.335938    -2.814453  \n",
       "2390489    -0.571289    -2.185547     0.627441  \n",
       "2390490     2.050781     1.725586     5.824219  \n",
       "\n",
       "[2390491 rows x 137 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.set_index(\"ts_id\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transforming the Dataset\n",
    "\n",
    "Now that the data is clean, we can start to prepare the data for the model. We first split the data into training and validation data (because this is Time Series, the last 10% of data will be taken as validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151441\n",
      "239050\n"
     ]
    }
   ],
   "source": [
    "# valid_index established above\n",
    "valid_df = train_df[valid_index:]\n",
    "train_df = train_df[0:valid_index]\n",
    "\n",
    "print(len(train_df.index))\n",
    "print(len(valid_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the features and our dependent variables, which are \"resp\" and the other \"resp\" over the various time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weight  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
      "0   0.000000          1  -1.873047  -2.191406  -0.474121  -0.322998   \n",
      "1  16.671875         -1  -1.349609  -1.705078   0.068054   0.028427   \n",
      "2   0.000000         -1   0.812988  -0.256104   0.806641   0.400146   \n",
      "3   0.000000         -1   1.174805   0.344727   0.066895   0.009354   \n",
      "4   0.138550          1  -3.171875  -3.093750  -0.161499  -0.128174   \n",
      "\n",
      "   feature_5  feature_6  feature_7  feature_8  ...  feature_120  feature_121  \\\n",
      "0   0.014687  -0.002483   0.576172   0.303711  ...     5.542969     2.095703   \n",
      "1   0.193848   0.138184   0.576172   0.303711  ...     5.542969     2.095703   \n",
      "2  -0.614258  -0.354736   0.576172   0.303711  ...     5.542969     2.095703   \n",
      "3  -1.006836  -0.676270   0.576172   0.303711  ...     5.542969     2.095703   \n",
      "4  -0.194946  -0.143799   0.576172   0.303711  ...     5.542969     2.095703   \n",
      "\n",
      "   feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
      "0     1.167969     8.312500     1.782227    14.015625     2.652344   \n",
      "1    -1.178711     1.777344    -0.915527     2.832031    -1.416992   \n",
      "2     6.117188     9.664062     5.542969    11.671875     7.281250   \n",
      "3     2.837891     0.499268     3.033203     1.513672     4.398438   \n",
      "4     0.344971     4.101562     0.614258     6.625000     0.800293   \n",
      "\n",
      "   feature_127  feature_128  feature_129  \n",
      "0    12.601562     2.300781    11.445312  \n",
      "1     2.296875    -1.304688     1.898438  \n",
      "2    10.062500     6.636719     9.429688  \n",
      "3     1.265625     3.855469     1.013672  \n",
      "4     5.234375     0.362549     3.925781  \n",
      "\n",
      "[5 rows x 131 columns]\n",
      "   resp  resp_1  resp_2  resp_3  resp_4\n",
      "0     1       1       1       1       1\n",
      "1     0       0       0       0       0\n",
      "2     1       1       1       1       1\n",
      "3     0       0       0       0       0\n",
      "4     0       1       1       0       0\n"
     ]
    }
   ],
   "source": [
    "train_Y = (train_df[[\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]] > 0).astype(int) # The model just has to predict whether the 'resp' value is positive or negative\n",
    "train_X = train_df.drop([\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\", \"date\", \"ts_id\"], axis=1)\n",
    "\n",
    "valid_Y = (valid_df[[\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\"]] > 0).astype(int)\n",
    "valid_X = valid_df.drop([\"resp\", \"resp_1\", \"resp_2\", \"resp_3\", \"resp_4\", \"date\", \"ts_id\"], axis=1)\n",
    "\n",
    "print(train_X.head())\n",
    "print(train_Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Windowing\n",
    "\n",
    "Next, we have to reshape our data for our model. Our model expects us to **window** our data for Time Series analysis. The final shape should be 3D, of the format **(batch_size, time_steps, feature_count)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# returns a tf.data.Dataset object\n",
    "def get_windowed_dataset(x_data, y_data, window_size, batch_size=4096, mode='train'):\n",
    "    x_ds = tf.data.Dataset.from_tensor_slices(x_data) # converting pandas Dataframe into tf.data.Dataset object\n",
    "    \n",
    "    x_ds = x_ds.window(window_size, shift=1)\n",
    "    x_ds = x_ds.flat_map(lambda window : window.batch(window_size, drop_remainder=True))\n",
    "    \n",
    "    if mode == 'train':\n",
    "        y_ds = tf.data.Dataset.from_tensor_slices(y_data[window_size:])\n",
    "        ds = tf.data.Dataset.zip((x_ds, y_ds))\n",
    "        ds = ds.shuffle(10000).batch(batch_size)\n",
    "    elif mode == 'predict':\n",
    "        ds = x_ds\n",
    "        ds = ds.batch(batch_size)\n",
    "        \n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 10 # The window_size is the lookback of the model\n",
    "\n",
    "train_ds = get_windowed_dataset(train_X, train_Y, lookback)\n",
    "valid_ds = get_windowed_dataset(valid_X, valid_Y, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(4096, 10, 131), dtype=float16, numpy=\n",
      "array([[[ 4.3125e+00, -1.0000e+00, -2.4922e+00, ..., -2.6836e+00,\n",
      "         -3.3828e+00, -2.2207e+00],\n",
      "        [ 3.9141e+00, -1.0000e+00,  7.9727e+00, ..., -2.6196e-01,\n",
      "          3.8613e+00,  2.2803e-01],\n",
      "        [ 6.3721e-02,  1.0000e+00,  5.5000e+00, ..., -8.6035e-01,\n",
      "          1.7168e+00, -5.3125e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  1.0000e+00, -1.7383e+00, ..., -1.5566e+00,\n",
      "         -1.8359e+00, -1.1484e+00],\n",
      "        [ 6.1182e-01,  1.0000e+00,  1.6650e+00, ..., -1.6426e+00,\n",
      "          7.3926e-01, -2.3223e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00, -5.8887e-01, ..., -1.9775e+00,\n",
      "         -7.6562e-01, -1.2666e+00]],\n",
      "\n",
      "       [[ 2.9570e+00, -1.0000e+00, -4.9976e-01, ...,  7.3145e-01,\n",
      "         -7.2559e-01,  5.4004e-01],\n",
      "        [ 0.0000e+00,  1.0000e+00, -1.8076e+00, ...,  5.6641e-01,\n",
      "         -8.4717e-01,  2.5732e-01],\n",
      "        [ 3.0640e-01, -1.0000e+00, -3.1719e+00, ..., -3.0518e-01,\n",
      "         -3.3997e-02, -5.4736e-01],\n",
      "        ...,\n",
      "        [ 4.0698e-01, -1.0000e+00,  2.8320e+00, ...,  1.5405e-01,\n",
      "          9.4043e-01, -1.9495e-01],\n",
      "        [ 2.2500e+00,  1.0000e+00,  4.9102e+00, ..., -1.3906e+00,\n",
      "         -1.2148e+00, -1.8926e+00],\n",
      "        [ 2.9570e+00,  1.0000e+00,  4.4609e+00, ...,  5.0244e-01,\n",
      "          6.5381e-01,  3.7061e-01]],\n",
      "\n",
      "       [[ 3.7070e+00,  1.0000e+00, -2.1252e-01, ..., -1.2314e+00,\n",
      "         -1.0176e+00, -1.1396e+00],\n",
      "        [ 2.9004e-01,  1.0000e+00, -3.1128e-01, ..., -1.4297e+00,\n",
      "         -1.0479e+00, -1.7637e+00],\n",
      "        [ 7.5439e-01, -1.0000e+00,  2.6777e+00, ..., -2.4043e+00,\n",
      "          1.0605e+00, -2.2109e+00],\n",
      "        ...,\n",
      "        [ 2.8955e-01, -1.0000e+00, -4.1479e-01, ..., -3.1055e+00,\n",
      "         -1.6387e+00, -2.7246e+00],\n",
      "        [ 1.1219e+01,  1.0000e+00,  6.2734e+00, ..., -8.4814e-01,\n",
      "          2.3914e-01, -6.7236e-01],\n",
      "        [ 0.0000e+00, -1.0000e+00,  7.7832e-01, ..., -2.0469e+00,\n",
      "         -1.5625e+00, -2.1211e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 9.2920e-01, -1.0000e+00, -3.1719e+00, ..., -2.3633e+00,\n",
      "          6.5479e-01, -2.2949e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00, -4.7412e-01, ..., -1.4590e+00,\n",
      "         -1.8613e+00, -9.4727e-01],\n",
      "        [ 6.0254e-01, -1.0000e+00,  1.7979e+00, ..., -9.8682e-01,\n",
      "          7.7490e-01, -1.5771e+00],\n",
      "        ...,\n",
      "        [ 9.2871e-01,  1.0000e+00,  8.9307e-01, ..., -7.5098e-01,\n",
      "          3.3105e+00, -8.0139e-02],\n",
      "        [ 2.5146e-01,  1.0000e+00, -8.9697e-01, ..., -1.8291e+00,\n",
      "          1.5928e+00, -2.9355e+00],\n",
      "        [ 1.3447e+00, -1.0000e+00,  4.1875e+00, ...,  2.1484e+00,\n",
      "          3.1582e+00,  3.9023e+00]],\n",
      "\n",
      "       [[ 3.5181e-01,  1.0000e+00,  1.7656e+00, ...,  7.9883e-01,\n",
      "          2.3340e+00, -4.2603e-01],\n",
      "        [ 0.0000e+00, -1.0000e+00,  2.3105e+00, ..., -1.2441e+00,\n",
      "          1.3203e+00, -9.5264e-01],\n",
      "        [ 0.0000e+00, -1.0000e+00, -2.2676e+00, ..., -1.0225e+00,\n",
      "         -1.6797e+00, -7.7490e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -1.0000e+00,  2.3926e+00, ..., -1.5176e+00,\n",
      "          1.6443e-01, -9.8047e-01],\n",
      "        [ 1.0117e+01, -1.0000e+00, -5.1221e-01, ..., -1.7568e+00,\n",
      "         -2.2012e+00, -1.7617e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  7.4219e+00, ..., -1.0029e+00,\n",
      "          6.3672e+00, -8.0322e-01]],\n",
      "\n",
      "       [[ 1.7539e+00, -1.0000e+00, -1.3516e+00, ...,  2.0020e+00,\n",
      "         -1.0840e-01,  2.4180e+00],\n",
      "        [ 1.4312e+01,  1.0000e+00,  7.2656e-01, ...,  1.5928e+00,\n",
      "         -3.7524e-01,  9.5117e-01],\n",
      "        [ 7.7812e+00, -1.0000e+00, -6.8408e-01, ...,  1.4294e-01,\n",
      "         -1.3242e+00, -1.7090e-01],\n",
      "        ...,\n",
      "        [ 1.4258e-01,  1.0000e+00,  3.8359e+00, ...,  1.2451e+00,\n",
      "          5.6523e+00,  1.1016e+00],\n",
      "        [ 4.7094e+01,  1.0000e+00,  2.6367e-01, ...,  3.9570e+00,\n",
      "          3.1104e-01,  2.4199e+00],\n",
      "        [ 7.2656e-01, -1.0000e+00,  9.7656e-02, ...,  1.7148e+00,\n",
      "          3.9531e+00,  1.5410e+00]]], dtype=float16)>, <tf.Tensor: shape=(4096, 5), dtype=int32, numpy=\n",
      "array([[0, 1, 1, 1, 0],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 0, 0, 1, 1],\n",
      "       ...,\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 1, 1]])>)\n",
      "(<tf.Tensor: shape=(4096, 10, 131), dtype=float16, numpy=\n",
      "array([[[ 0.     , -1.     , -2.193  , ..., -1.057  , -1.501  ,\n",
      "         -0.516  ],\n",
      "        [ 0.     ,  1.     ,  0.4858 , ..., -1.343  , -1.337  ,\n",
      "         -1.677  ],\n",
      "        [10.24   , -1.     , -2.016  , ..., -0.993  , -2.291  ,\n",
      "         -0.8096 ],\n",
      "        ...,\n",
      "        [ 2.518  ,  1.     ,  3.064  , ..., -1.006  ,  1.539  ,\n",
      "         -0.07526],\n",
      "        [ 7.09   , -1.     ,  2.33   , ..., -1.291  ,  1.412  ,\n",
      "         -1.749  ],\n",
      "        [ 0.     ,  1.     , -1.566  , ..., -1.358  ,  1.775  ,\n",
      "         -1.377  ]],\n",
      "\n",
      "       [[ 1.513  ,  1.     , -0.1626 , ..., -2.125  , -0.5986 ,\n",
      "         -2.33   ],\n",
      "        [ 2.158  , -1.     ,  2.346  , ..., -0.784  ,  2.16   ,\n",
      "         -0.842  ],\n",
      "        [ 1.973  ,  1.     ,  1.338  , ..., -2.787  , -0.5117 ,\n",
      "         -2.193  ],\n",
      "        ...,\n",
      "        [ 0.2384 , -1.     ,  1.249  , ..., -2.088  ,  0.5938 ,\n",
      "         -1.73   ],\n",
      "        [ 1.381  , -1.     , -3.172  , ...,  0.268  ,  8.07   ,\n",
      "          2.496  ],\n",
      "        [ 3.533  ,  1.     , -1.128  , ..., -2.332  , -2.428  ,\n",
      "         -1.995  ]],\n",
      "\n",
      "       [[ 0.9473 ,  1.     ,  0.3552 , ..., -2.643  , -0.907  ,\n",
      "         -2.475  ],\n",
      "        [ 1.597  ,  1.     , -0.08746, ..., -2.418  , -1.01   ,\n",
      "         -2.225  ],\n",
      "        [ 1.74   ,  1.     , -1.605  , ..., -1.938  , -1.448  ,\n",
      "         -1.373  ],\n",
      "        ...,\n",
      "        [ 0.2202 , -1.     ,  0.994  , ..., -1.072  ,  3.465  ,\n",
      "         -0.1727 ],\n",
      "        [ 0.     ,  1.     ,  0.56   , ..., -2.408  , -0.8564 ,\n",
      "         -2.268  ],\n",
      "        [ 4.156  ,  1.     ,  1.2    , ..., -2.182  ,  0.2644 ,\n",
      "         -1.056  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 6.85   , -1.     ,  0.893  , ..., -0.507  ,  0.2039 ,\n",
      "         -0.3237 ],\n",
      "        [ 4.613  , -1.     ,  0.9717 , ...,  1.193  , -1.211  ,\n",
      "          0.847  ],\n",
      "        [ 0.7085 ,  1.     , -1.067  , ...,  1.634  ,  0.7773 ,\n",
      "          1.929  ],\n",
      "        ...,\n",
      "        [ 2.55   , -1.     ,  3.008  , ...,  0.6846 , -0.2703 ,\n",
      "          0.475  ],\n",
      "        [ 1.355  ,  1.     ,  6.027  , ..., -1.068  ,  3.021  ,\n",
      "         -1.016  ],\n",
      "        [ 0.     ,  1.     ,  0.4875 , ...,  3.672  ,  7.492  ,\n",
      "          3.531  ]],\n",
      "\n",
      "       [[ 1.265  , -1.     , -0.557  , ..., -0.9907 ,  4.297  ,\n",
      "         -1.216  ],\n",
      "        [ 0.0904 ,  1.     , -3.172  , ..., -1.059  ,  1.638  ,\n",
      "         -0.7656 ],\n",
      "        [ 0.321  , -1.     , -0.2095 , ...,  1.5205 , -0.087  ,\n",
      "          1.068  ],\n",
      "        ...,\n",
      "        [ 0.628  ,  1.     ,  0.4434 , ..., -0.0945 , -0.1008 ,\n",
      "         -0.3276 ],\n",
      "        [ 0.     ,  1.     ,  0.6353 , ...,  0.9614 ,  2.262  ,\n",
      "          0.1549 ],\n",
      "        [ 1.049  , -1.     , -0.4106 , ...,  0.7114 , -0.2018 ,\n",
      "          0.7183 ]],\n",
      "\n",
      "       [[ 0.4868 ,  1.     , -0.8384 , ...,  5.31   ,  1.25   ,\n",
      "          4.74   ],\n",
      "        [ 6.207  ,  1.     ,  2.965  , ...,  2.342  ,  1.05   ,\n",
      "          2.352  ],\n",
      "        [ 0.     ,  1.     , -0.3035 , ...,  2.08   , -1.02   ,\n",
      "          1.889  ],\n",
      "        ...,\n",
      "        [ 0.562  , -1.     , -3.172  , ...,  3.186  , -0.714  ,\n",
      "          3.508  ],\n",
      "        [ 0.1996 ,  1.     , -3.172  , ...,  6.137  ,  1.376  ,\n",
      "          6.355  ],\n",
      "        [ 1.347  , -1.     ,  2.393  , ...,  0.716  ,  1.703  ,\n",
      "          0.7188 ]]], dtype=float16)>, <tf.Tensor: shape=(4096, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 0],\n",
      "       ...,\n",
      "       [1, 0, 0, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [0, 1, 1, 1, 0]])>)\n",
      "(<tf.Tensor: shape=(4096, 10, 131), dtype=float16, numpy=\n",
      "array([[[ 0.     ,  1.     , -0.7783 , ...,  0.01823, -0.1759 ,\n",
      "         -0.8716 ],\n",
      "        [ 0.1076 ,  1.     ,  1.236  , ...,  0.01833, -0.1719 ,\n",
      "         -0.869  ],\n",
      "        [ 0.4265 , -1.     ,  0.718  , ..., -1.828  ,  2.145  ,\n",
      "         -0.812  ],\n",
      "        ...,\n",
      "        [ 3.297  ,  1.     ,  1.827  , ..., -1.143  ,  0.0379 ,\n",
      "         -0.947  ],\n",
      "        [ 3.412  , -1.     , -2.203  , ..., -1.303  , -2.389  ,\n",
      "         -1.428  ],\n",
      "        [ 1.565  ,  1.     ,  0.3613 , ..., -0.873  ,  0.7583 ,\n",
      "         -0.675  ]],\n",
      "\n",
      "       [[ 0.281  ,  1.     ,  1.588  , ...,  1.987  ,  3.15   ,\n",
      "          1.623  ],\n",
      "        [ 0.09674,  1.     ,  1.274  , ...,  1.987  ,  3.158  ,\n",
      "          1.625  ],\n",
      "        [ 0.1041 ,  1.     , -1.236  , ...,  0.0909 ,  1.866  ,\n",
      "          0.2499 ],\n",
      "        ...,\n",
      "        [ 1.219  ,  1.     , -1.778  , ...,  0.816  , -0.965  ,\n",
      "          1.157  ],\n",
      "        [ 0.     ,  1.     ,  9.07   , ...,  0.1992 ,  3.53   ,\n",
      "          0.1833 ],\n",
      "        [ 0.     ,  1.     ,  8.51   , ...,  0.1995 ,  3.549  ,\n",
      "          0.1887 ]],\n",
      "\n",
      "       [[ 0.1521 ,  1.     , -3.172  , ...,  1.795  ,  2.932  ,\n",
      "          2.314  ],\n",
      "        [ 3.4    , -1.     ,  1.634  , ..., -0.2451 ,  1.64   ,\n",
      "         -0.2734 ],\n",
      "        [ 9.445  , -1.     , -0.2095 , ..., -1.695  , -0.4526 ,\n",
      "         -1.177  ],\n",
      "        ...,\n",
      "        [ 0.     , -1.     , -0.3843 , ..., -0.0799 , -0.248  ,\n",
      "          0.1794 ],\n",
      "        [ 5.18   , -1.     ,  2.568  , ..., -1.061  , -0.5923 ,\n",
      "         -1.424  ],\n",
      "        [ 9.945  ,  1.     ,  5.67   , ..., -0.9307 , -1.401  ,\n",
      "         -1.001  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 4.95   ,  1.     ,  3.547  , ...,  5.684  ,  3.91   ,\n",
      "          3.904  ],\n",
      "        [ 0.     , -1.     , -0.88   , ..., -0.4226 , -0.593  ,\n",
      "         -0.2201 ],\n",
      "        [ 4.55   , -1.     ,  0.9214 , ...,  1.025  ,  0.959  ,\n",
      "          1.472  ],\n",
      "        ...,\n",
      "        [ 0.     ,  1.     ,  7.54   , ...,  1.11   ,  4.84   ,\n",
      "          1.106  ],\n",
      "        [ 0.3206 ,  1.     ,  6.016  , ...,  5.17   ,  3.31   ,\n",
      "          3.188  ],\n",
      "        [ 0.1937 , -1.     , -1.372  , ...,  0.6187 ,  1.371  ,\n",
      "          0.05624]],\n",
      "\n",
      "       [[ 0.4033 , -1.     ,  0.3008 , ..., -0.56   ,  2.96   ,\n",
      "         -0.288  ],\n",
      "        [ 2.719  ,  1.     , -1.641  , ..., -0.689  , -3.648  ,\n",
      "         -1.844  ],\n",
      "        [ 0.     ,  1.     ,  1.141  , ..., -0.928  , -0.722  ,\n",
      "         -0.7373 ],\n",
      "        ...,\n",
      "        [ 0.09326, -1.     ,  5.715  , ...,  0.4658 ,  1.378  ,\n",
      "          0.6357 ],\n",
      "        [ 0.     ,  1.     ,  0.4573 , ..., -0.6514 ,  0.833  ,\n",
      "         -1.164  ],\n",
      "        [ 0.2703 , -1.     ,  1.314  , ..., -0.9004 ,  0.612  ,\n",
      "         -1.381  ]],\n",
      "\n",
      "       [[ 0.3853 , -1.     ,  3.338  , ...,  0.03967,  0.5405 ,\n",
      "          0.1628 ],\n",
      "        [ 0.1378 ,  1.     ,  0.4978 , ..., -0.6387 ,  1.001  ,\n",
      "         -0.3792 ],\n",
      "        [ 0.     ,  1.     , -0.98   , ..., -0.4104 , -2.457  ,\n",
      "         -1.071  ],\n",
      "        ...,\n",
      "        [ 5.02   ,  1.     ,  3.215  , ..., -0.3022 ,  1.285  ,\n",
      "         -0.876  ],\n",
      "        [ 0.4343 , -1.     ,  1.184  , ..., -0.4653 ,  1.167  ,\n",
      "          0.137  ],\n",
      "        [ 0.3132 ,  1.     , -0.2145 , ..., -1.385  ,  0.3042 ,\n",
      "         -0.8564 ]]], dtype=float16)>, <tf.Tensor: shape=(4096, 5), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 1, 1],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0],\n",
      "       ...,\n",
      "       [1, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 1, 1]])>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(4096, 10, 131), dtype=float16, numpy=\n",
      "array([[[ 3.6152e+00, -1.0000e+00,  1.9414e+00, ...,  1.0170e-02,\n",
      "          9.3933e-02, -8.9453e-01],\n",
      "        [ 7.9688e-01,  1.0000e+00, -1.7695e+00, ...,  8.7585e-02,\n",
      "         -2.2285e+00, -1.1646e-01],\n",
      "        [ 2.1738e+00, -1.0000e+00,  1.0029e+00, ..., -1.0869e+00,\n",
      "         -1.0283e+00, -9.2236e-01],\n",
      "        ...,\n",
      "        [ 6.6357e-01,  1.0000e+00,  8.1152e-01, ...,  1.0537e+00,\n",
      "         -2.0374e-01,  3.4033e-01],\n",
      "        [ 4.4141e+00, -1.0000e+00, -4.0820e-01, ...,  2.1211e+00,\n",
      "         -3.0737e-01,  4.0649e-01],\n",
      "        [ 0.0000e+00,  1.0000e+00,  2.7012e+00, ..., -1.3269e-01,\n",
      "          9.2725e-01, -8.4814e-01]],\n",
      "\n",
      "       [[ 1.7981e-01, -1.0000e+00,  3.4004e+00, ...,  1.1250e+00,\n",
      "          1.5645e+00,  7.8906e-01],\n",
      "        [ 2.2144e-01, -1.0000e+00, -3.1719e+00, ..., -9.7900e-01,\n",
      "          6.4453e+00, -1.3398e+00],\n",
      "        [ 3.5234e+00,  1.0000e+00, -2.0471e-01, ..., -3.8135e-01,\n",
      "         -1.8848e+00, -1.3672e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  1.0000e+00, -1.9814e+00, ...,  4.2734e+00,\n",
      "          1.2832e+00,  3.4492e+00],\n",
      "        [ 4.3188e-01, -1.0000e+00, -5.5713e-01, ...,  9.6191e-01,\n",
      "         -1.1416e+00,  1.0098e+00],\n",
      "        [ 3.5864e-01,  1.0000e+00, -1.9414e+00, ..., -4.7290e-01,\n",
      "         -1.5537e+00, -4.6265e-01]],\n",
      "\n",
      "       [[ 1.6348e+00,  1.0000e+00, -1.5947e+00, ...,  9.9854e-01,\n",
      "         -1.0459e+00,  9.6631e-01],\n",
      "        [ 0.0000e+00,  1.0000e+00,  1.0352e+00, ..., -1.0020e+00,\n",
      "          9.1113e-01, -7.7197e-01],\n",
      "        [ 1.9016e+01,  1.0000e+00, -1.7822e-02, ..., -5.4736e-01,\n",
      "         -1.9707e+00, -3.8086e-02],\n",
      "        ...,\n",
      "        [ 1.8797e+01,  1.0000e+00, -7.4219e-01, ..., -4.0918e-01,\n",
      "         -1.8105e+00,  2.3853e-01],\n",
      "        [ 9.8535e-01,  1.0000e+00,  6.0469e+00, ..., -1.4707e+00,\n",
      "          1.9004e+00, -1.2227e+00],\n",
      "        [ 6.5625e-01, -1.0000e+00,  2.4648e+00, ..., -9.7217e-01,\n",
      "          6.9287e-01, -9.3750e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 2.6191e+00, -1.0000e+00,  1.3799e+00, ...,  8.6243e-02,\n",
      "         -3.1201e-01,  1.3682e+00],\n",
      "        [ 1.3145e+00, -1.0000e+00,  4.1445e+00, ..., -5.9814e-01,\n",
      "          6.3984e+00, -3.6255e-01],\n",
      "        [ 4.2812e+00, -1.0000e+00,  4.4067e-01, ..., -1.8994e-01,\n",
      "         -1.9980e+00, -6.2598e-01],\n",
      "        ...,\n",
      "        [ 4.8477e+00,  1.0000e+00, -7.1338e-01, ..., -1.1709e+00,\n",
      "         -3.0371e+00, -1.3838e+00],\n",
      "        [ 3.1453e+01, -1.0000e+00, -4.2511e-02, ...,  6.1719e+00,\n",
      "          8.4912e-01,  6.5703e+00],\n",
      "        [ 0.0000e+00, -1.0000e+00, -7.5537e-01, ...,  6.1680e+00,\n",
      "          8.4180e-01,  6.5547e+00]],\n",
      "\n",
      "       [[ 2.1765e-01,  1.0000e+00,  2.6099e-01, ...,  2.3535e+00,\n",
      "          3.2666e-01,  1.7266e+00],\n",
      "        [ 1.0615e+00,  1.0000e+00,  9.0186e-01, ...,  4.4800e-01,\n",
      "          5.2578e+00,  1.1689e+00],\n",
      "        [ 1.8555e+00, -1.0000e+00,  8.4131e-01, ...,  7.4883e+00,\n",
      "          3.5898e+00,  4.8359e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -1.0000e+00, -1.0068e+00, ...,  3.2891e+00,\n",
      "         -1.0205e+00,  2.0781e+00],\n",
      "        [ 7.4951e-01,  1.0000e+00,  1.3350e+00, ...,  6.4297e+00,\n",
      "          5.4297e+00,  6.0469e+00],\n",
      "        [ 0.0000e+00, -1.0000e+00, -3.5596e-01, ...,  2.1406e+00,\n",
      "         -2.8003e-01,  1.6475e+00]],\n",
      "\n",
      "       [[ 4.4873e-01, -1.0000e+00,  7.4727e+00, ..., -8.5205e-01,\n",
      "          1.6211e+00, -2.2363e-01],\n",
      "        [ 3.0469e-01,  1.0000e+00, -1.6174e-01, ..., -1.5205e+00,\n",
      "         -1.3359e+00, -2.1289e+00],\n",
      "        [ 2.8340e+00, -1.0000e+00,  2.2969e+00, ..., -2.3496e+00,\n",
      "          1.8689e-01, -2.0781e+00],\n",
      "        ...,\n",
      "        [ 1.9019e-01,  1.0000e+00, -3.1719e+00, ...,  4.6094e-01,\n",
      "         -1.7920e+00,  1.4148e-01],\n",
      "        [ 0.0000e+00,  1.0000e+00, -6.5088e-01, ..., -1.1006e+00,\n",
      "         -1.9883e+00, -8.6426e-01],\n",
      "        [ 5.9375e-01,  1.0000e+00, -1.2471e+00, ...,  1.3062e-01,\n",
      "          2.5645e+00,  6.9287e-01]]], dtype=float16)>, <tf.Tensor: shape=(4096, 5), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       ...,\n",
      "       [0, 1, 1, 1, 0],\n",
      "       [1, 0, 0, 0, 1],\n",
      "       [0, 1, 1, 1, 0]])>)\n",
      "(<tf.Tensor: shape=(4096, 10, 131), dtype=float16, numpy=\n",
      "array([[[ 2.9980e+00, -1.0000e+00, -1.6318e+00, ...,  2.8760e-01,\n",
      "         -2.1436e-01,  5.5713e-01],\n",
      "        [ 8.3301e-01, -1.0000e+00, -2.6929e-01, ...,  2.1152e+00,\n",
      "          3.5566e+00,  2.0254e+00],\n",
      "        [ 4.8633e+00, -1.0000e+00,  2.9824e+00, ..., -1.5303e+00,\n",
      "         -3.3325e-01, -2.0918e+00],\n",
      "        ...,\n",
      "        [ 3.5840e+00,  1.0000e+00,  4.8906e+00, ...,  9.1406e-01,\n",
      "          4.7305e+00,  7.3535e-01],\n",
      "        [ 0.0000e+00, -1.0000e+00, -2.3547e-01, ..., -3.9825e-02,\n",
      "         -7.4902e-01, -3.5083e-01],\n",
      "        [ 2.8109e+01,  1.0000e+00,  1.8848e-01, ..., -9.1748e-01,\n",
      "         -1.0283e+00, -9.1992e-01]],\n",
      "\n",
      "       [[ 5.3906e-01, -1.0000e+00,  2.2715e+00, ...,  5.7891e+00,\n",
      "          2.8369e-01,  5.2539e+00],\n",
      "        [ 1.4648e+00,  1.0000e+00,  1.7998e+00, ...,  2.1914e+00,\n",
      "          6.5088e-01,  5.6494e-01],\n",
      "        [ 2.6172e-01, -1.0000e+00,  1.0049e+00, ...,  2.9961e+00,\n",
      "          1.0039e+00,  2.0918e+00],\n",
      "        ...,\n",
      "        [ 6.4258e-01,  1.0000e+00, -4.1162e-01, ...,  2.2988e+00,\n",
      "          1.9521e+00,  2.1660e+00],\n",
      "        [ 7.1875e-01, -1.0000e+00, -1.1260e+00, ...,  1.6914e+00,\n",
      "          3.4434e+00,  1.3105e+00],\n",
      "        [ 3.0103e-01, -1.0000e+00,  2.3000e+01, ...,  2.9277e+00,\n",
      "          9.0469e+00,  7.9297e-01]],\n",
      "\n",
      "       [[ 1.4092e+00, -1.0000e+00, -6.1475e-01, ..., -7.8857e-01,\n",
      "         -4.8364e-01, -3.0493e-01],\n",
      "        [ 3.6133e-01, -1.0000e+00,  3.7085e-01, ..., -5.1953e-01,\n",
      "          6.0273e+00, -8.9050e-02],\n",
      "        [ 0.0000e+00, -1.0000e+00, -1.4033e+00, ..., -8.9941e-01,\n",
      "         -2.7402e+00, -1.0078e+00],\n",
      "        ...,\n",
      "        [ 9.6484e-01, -1.0000e+00, -2.2192e-01, ..., -1.4326e+00,\n",
      "          2.6523e+00, -1.2246e+00],\n",
      "        [ 1.6357e+00, -1.0000e+00, -1.9111e+00, ..., -9.8828e-01,\n",
      "         -1.9482e+00, -5.1270e-01],\n",
      "        [ 1.8225e-01, -1.0000e+00, -3.1719e+00, ..., -1.4932e+00,\n",
      "          2.2285e+00, -1.5137e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 9.0479e-01,  1.0000e+00,  1.8428e+00, ...,  1.3389e+00,\n",
      "         -2.8782e-03,  1.1221e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  1.2344e+01, ..., -1.8372e-01,\n",
      "          3.4512e+00, -7.8174e-01],\n",
      "        [ 1.4082e+00,  1.0000e+00,  5.3418e-01, ..., -3.1934e-01,\n",
      "          1.7568e+00, -4.0771e-01],\n",
      "        ...,\n",
      "        [ 4.8999e-01,  1.0000e+00,  7.5000e+00, ...,  1.7637e+00,\n",
      "          5.2578e+00,  1.9990e+00],\n",
      "        [ 2.0645e+00,  1.0000e+00,  1.5266e+01, ...,  1.5820e+00,\n",
      "          2.7012e+00,  9.4287e-01],\n",
      "        [ 1.4600e+00, -1.0000e+00,  2.4531e+00, ..., -3.2275e-01,\n",
      "          3.8125e+00, -9.6619e-02]],\n",
      "\n",
      "       [[ 9.7119e-01,  1.0000e+00,  1.1719e+00, ...,  1.2285e+00,\n",
      "         -4.9292e-01,  1.1816e+00],\n",
      "        [ 1.9250e-01, -1.0000e+00, -3.1719e+00, ...,  1.2285e+00,\n",
      "         -4.9268e-01,  1.1807e+00],\n",
      "        [ 1.8250e-01, -1.0000e+00, -3.1719e+00, ..., -1.3379e+00,\n",
      "         -8.5596e-01, -4.4482e-01],\n",
      "        ...,\n",
      "        [ 2.3828e+00, -1.0000e+00,  3.5918e+00, ...,  4.3906e+00,\n",
      "          7.2461e-01,  3.9473e+00],\n",
      "        [ 7.4756e-01,  1.0000e+00, -3.1719e+00, ...,  4.3945e+00,\n",
      "          7.3096e-01,  3.9609e+00],\n",
      "        [ 2.8101e-01, -1.0000e+00,  2.1074e+00, ...,  4.3984e+00,\n",
      "          7.3291e-01,  3.9668e+00]],\n",
      "\n",
      "       [[ 1.2520e+00, -1.0000e+00,  2.0664e+00, ..., -1.1885e+00,\n",
      "          2.6367e+00, -9.3359e-01],\n",
      "        [ 1.2256e+00,  1.0000e+00,  5.5273e-01, ...,  2.5659e-01,\n",
      "          1.9639e+00,  3.0444e-01],\n",
      "        [ 4.7339e-01,  1.0000e+00,  7.2344e+00, ...,  1.3662e+00,\n",
      "          7.7031e+00,  1.5498e+00],\n",
      "        ...,\n",
      "        [ 2.8262e+00,  1.0000e+00,  3.2471e-01, ..., -1.3096e+00,\n",
      "          2.0059e+00, -4.3262e-01],\n",
      "        [ 0.0000e+00,  1.0000e+00, -1.0908e+00, ..., -1.0488e+00,\n",
      "          4.2383e-01, -5.3223e-01],\n",
      "        [ 1.4221e-01, -1.0000e+00, -7.2998e-01, ..., -1.2314e+00,\n",
      "          3.1074e+00, -1.0352e+00]]], dtype=float16)>, <tf.Tensor: shape=(4096, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [0, 1, 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "for line in train_ds.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building and Training the Model\n",
    "\n",
    "We will then start building the model. I use Keras to build a LSTM model, using Adam as the optimizer, Binary-Crossentropy as the loss, and AUC-ROC and accuracy as the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_lstm(lookback, num_columns, num_labels, lstm_units, dense_units, dropout_rate, learning_rate, label_smoothing):\n",
    "    inp = layers.Input(shape=(lookback, num_columns, )) # Timestep=None to ensure that the model works even when data is less than the ideal lookback length\n",
    "    x = layers.BatchNormalization()(inp)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    for i in range(len(lstm_units)):\n",
    "        x = layers.LSTM(lstm_units[i], return_state=False, return_sequences=(False if i==len(lstm_units)-1 else True))(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "    for j in range(len(dense_units)):\n",
    "        x = layers.Dense(dense_units[j])(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x = layers.Dense(num_labels)(x)\n",
    "    out = layers.Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inp, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "                  metrics=['AUC', 'accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 131)]         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 131)           524       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 131)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 64)            50176     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 252,689\n",
      "Trainable params: 250,891\n",
      "Non-trainable params: 1,798\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "526/526 [==============================] - 682s 1s/step - loss: 0.7075 - auc: 0.5027 - accuracy: 0.1980 - val_loss: 0.6928 - val_auc: 0.5091 - val_accuracy: 0.0920\n",
      "Epoch 2/20\n",
      "526/526 [==============================] - 681s 1s/step - loss: 0.6929 - auc: 0.5070 - accuracy: 0.1597 - val_loss: 0.6927 - val_auc: 0.5107 - val_accuracy: 0.1100\n",
      "Epoch 3/20\n",
      "526/526 [==============================] - 680s 1s/step - loss: 0.6928 - auc: 0.5078 - accuracy: 0.1489 - val_loss: 0.6928 - val_auc: 0.5104 - val_accuracy: 0.0921\n",
      "Epoch 4/20\n",
      "526/526 [==============================] - 744s 1s/step - loss: 0.6928 - auc: 0.5077 - accuracy: 0.1427 - val_loss: 0.6927 - val_auc: 0.5106 - val_accuracy: 0.1105\n",
      "Epoch 5/20\n",
      "526/526 [==============================] - 726s 1s/step - loss: 0.6927 - auc: 0.5088 - accuracy: 0.1465 - val_loss: 0.6926 - val_auc: 0.5112 - val_accuracy: 0.0860\n",
      "Epoch 6/20\n",
      "526/526 [==============================] - 682s 1s/step - loss: 0.6927 - auc: 0.5088 - accuracy: 0.1513 - val_loss: 0.6926 - val_auc: 0.5120 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "526/526 [==============================] - 700s 1s/step - loss: 0.6927 - auc: 0.5095 - accuracy: 0.1505 - val_loss: 0.6926 - val_auc: 0.5115 - val_accuracy: 0.0584\n",
      "Epoch 8/20\n",
      "526/526 [==============================] - 642s 1s/step - loss: 0.6926 - auc: 0.5102 - accuracy: 0.1539 - val_loss: 0.6927 - val_auc: 0.5114 - val_accuracy: 0.0478\n",
      "Epoch 9/20\n",
      "526/526 [==============================] - 635s 1s/step - loss: 0.6927 - auc: 0.5105 - accuracy: 0.1452 - val_loss: 0.6925 - val_auc: 0.5124 - val_accuracy: 0.0361\n",
      "Epoch 10/20\n",
      "526/526 [==============================] - 3039s 6s/step - loss: 0.6926 - auc: 0.5113 - accuracy: 0.1445 - val_loss: 0.6926 - val_auc: 0.5123 - val_accuracy: 0.0837\n",
      "Epoch 11/20\n",
      "526/526 [==============================] - 681s 1s/step - loss: 0.6925 - auc: 0.5119 - accuracy: 0.1444 - val_loss: 0.6925 - val_auc: 0.5125 - val_accuracy: 0.0509\n",
      "Epoch 12/20\n",
      "526/526 [==============================] - 652s 1s/step - loss: 0.6926 - auc: 0.5119 - accuracy: 0.1403 - val_loss: 0.6925 - val_auc: 0.5128 - val_accuracy: 0.0822\n",
      "Epoch 13/20\n",
      "526/526 [==============================] - 18988s 36s/step - loss: 0.6925 - auc: 0.5120 - accuracy: 0.1458 - val_loss: 0.6926 - val_auc: 0.5119 - val_accuracy: 0.0482\n",
      "Epoch 14/20\n",
      "526/526 [==============================] - 47142s 90s/step - loss: 0.6925 - auc: 0.5121 - accuracy: 0.1447 - val_loss: 0.6925 - val_auc: 0.5131 - val_accuracy: 0.1271\n",
      "Epoch 15/20\n",
      "526/526 [==============================] - 557s 1s/step - loss: 0.6925 - auc: 0.5132 - accuracy: 0.1496 - val_loss: 0.6926 - val_auc: 0.5121 - val_accuracy: 0.1228\n",
      "Epoch 16/20\n",
      "526/526 [==============================] - 598s 1s/step - loss: 0.6924 - auc: 0.5136 - accuracy: 0.1438 - val_loss: 0.6927 - val_auc: 0.5126 - val_accuracy: 0.0926\n",
      "Epoch 17/20\n",
      "526/526 [==============================] - 576s 1s/step - loss: 0.6924 - auc: 0.5136 - accuracy: 0.1338 - val_loss: 0.6926 - val_auc: 0.5130 - val_accuracy: 0.0964\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7935b8f40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model has been tuned\n",
    "num_epochs = 20\n",
    "\n",
    "num_columns = len(train_X.columns)\n",
    "num_labels = len(train_Y.columns)\n",
    "lstm_units = [64, 64]\n",
    "dense_units = [512, 256]\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001\n",
    "label_smoothing = 0.01\n",
    "\n",
    "# Early stopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "\n",
    "lstm_model = build_lstm(lookback, num_columns, num_labels, lstm_units, dense_units, dropout_rate, learning_rate, label_smoothing)\n",
    "lstm_model.fit(train_ds, validation_data=(valid_ds), epochs=num_epochs, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission\n",
    "\n",
    "Using the Jane Street Time-series API, we set up our notebook for submission to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object for keeping track of the windowed data\n",
    "class DataWindower:\n",
    "    def __init__(self, lookback, discrete_features):\n",
    "        self.data = pd.DataFrame()\n",
    "        self.cols = None\n",
    "        self.lookback = lookback\n",
    "        self.discrete_features = discrete_features\n",
    "        \n",
    "    def add_data(self, data):\n",
    "        if self.data.empty:\n",
    "            data = np.nan_to_num(data) + np.isnan(data) * f_mean # Dealing with NaN entries\n",
    "            self.data = pd.concat([data for _ in range(self.lookback)], axis=0) # Filling all rows with copies of the first data entry\n",
    "            self.cols = self.data.columns\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            data = self.__fill_na_mean_discrete(data) # Dealing with discrete NaN entries\n",
    "            data = np.nan_to_num(data) + np.isnan(data) * self.data.loc[len(self.data)-1] # Dealing with continuous NaN entries\n",
    "            self.data = pd.concat([self.data, data], axis=0)\n",
    "            self.data.drop(0, axis=0, inplace=True) # Ensuring that the data window is always of lookback length\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "    def __fill_na_mean_discrete(self, data):\n",
    "        data[self.discrete_features] = data[self.discrete_features].fillna(value=f_mean[self.discrete_features])\n",
    "        return data\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data.values.reshape(1, self.data.shape[0], self.data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Kernel only\n",
    "import janestreet\n",
    "env = janestreet.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # an iterator which loops over the test set\n",
    "\n",
    "data_w = DataWindower(lookback, discrete_features)\n",
    "threshold = 0.500\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    data_w.add_data(test_df.drop('date', axis=1))\n",
    "    \n",
    "    if test_df['weight'].values > 0:\n",
    "        prediction = lstm_model.predict(data_w.get_data())\n",
    "        avg = np.sum(prediction) / prediction.size\n",
    "        sample_prediction_df.action = 1 if avg > threshold else 0\n",
    "    else:\n",
    "        sample_prediction_df.action = 0\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Notes and Observations\n",
    "\n",
    "Despite my initial optimism that an LSTM will be an improvement over simply using a standard multi-layer perceptron (MLP), the model did not perform well. The AUC-ROC was very close to 0.5, indicating that the model had little to no distinguishing power, even on the training data. The accuracy was also low, hovering around 15-20%.\n",
    "\n",
    "The poor performance might be due to the very short time between each data point. A lookback of 10, 50 or even 100 will only retain data from a short period of time into the past. In contrast, Fundamental Analysis tends to look at data going back hours, days or weeks. With such a short lookback, the data is also likely very noisy.\n",
    "\n",
    "This LSTM approach was also much more resource-intensive than simpler approaches, due to the windowing of the data increasing the size of the data processed by a factor of the lookback value and the complexity of an LSTM model relative to a MLP. This limited the amount of tuning and epochs I could run due to Kaggle Notebooks' computing limitations.\n",
    " \n",
    "Ultimately, I conclude that the model, as it is, is ill-suited for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://www.kaggle.com/carlmcbrideellis/jane-street-eda-of-day-0-and-feature-importance\n",
    "\n",
    "https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day\n",
    "\n",
    "https://www.kaggle.com/manavtrivedi/lstm-rnn-classifier\n",
    "\n",
    "https://www.kaggle.com/rajkumarl/jane-tf-keras-lstm\n",
    "\n",
    "https://www.kaggle.com/tarlannazarov/own-jane-street-with-keras-nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
